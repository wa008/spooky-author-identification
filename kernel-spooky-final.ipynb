{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### 进展\n",
    "1. 验证集准确率达到63%\n",
    "2. 添加drop层，drop_rate=0.2，准确率提升到71%\n",
    "\n",
    "### 存在的问题\n",
    "1. lstm中使用隐藏层的最后一层作为下一层的输入，而不是输出层作为下一层的输入\n",
    "2. 只使用了文本的前100个单词用作数据集的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "1ee9febb-0802-4634-97c4-6b4cc84aae5c",
    "_uuid": "7fdd7bca-d093-4d10-9c11-bc1c59f6778d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/glove840b300dtxt-spooky/glove840b300dtxt_now.txt\n",
      "/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\n",
      "/kaggle/input/spooky-author-identification/sample_submission.zip\n",
      "/kaggle/input/spooky-author-identification/train.zip\n",
      "/kaggle/input/spooky-author-identification/test.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "f9c82180-420f-44b9-8dcd-044952961c5a",
    "_uuid": "a375e8de-2093-4e67-8c7d-0fcd2b1a02ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import psutil\n",
    "import gc\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "# from sklearn.externals import joblib\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from glob import glob\n",
    "from sys import getsizeof\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchtext import data, datasets\n",
    "from nltk import ngrams\n",
    "from torchtext.vocab import GloVe, Vectors\n",
    "from collections import defaultdict\n",
    "data_path = '/kaggle/input/spooky-author-identification/'\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from torch.utils.data import DataLoader\n",
    "import nltk\n",
    "stop_words = stopwords.words('english')\n",
    "from torch.nn import utils as nn_utils\n",
    "print (torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "4073bf87-af04-49c9-afd1-42131aabc326",
    "_uuid": "436dd002-59d9-4cc0-87dd-7493e5c51ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 3) (8392, 2) (8392, 4)\n",
      "        id                                               text author\n",
      "0  id26305  This process, however, afforded me no means of...    EAP\n",
      "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
      "2  id11008  In his left hand was a gold snuff box, from wh...    EAP \n",
      "\n",
      "         id                                               text\n",
      "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
      "1  id24541  If a fire wanted fanning, it could readily be ...\n",
      "2  id00134  And when they had broken down the frail door t... \n",
      "\n",
      "         id       EAP       HPL       MWS\n",
      "0  id02310  0.403494  0.287808  0.308698\n",
      "1  id24541  0.403494  0.287808  0.308698\n",
      "2  id00134  0.403494  0.287808  0.308698\n",
      "(15663,)\n",
      "(3916,)\n",
      "(8392,)\n"
     ]
    }
   ],
   "source": [
    "def read_data(row = None):\n",
    "    df_train = pd.read_csv(data_path + 'train.zip', nrows = row)\n",
    "    df_test = pd.read_csv(data_path + 'test.zip', nrows = row)\n",
    "    df_sub = pd.read_csv(data_path + 'sample_submission.zip', nrows = row)\n",
    "    return df_train, df_test, df_sub\n",
    "df_train, df_test, df_sub = read_data()\n",
    "print (df_train.shape, df_test.shape, df_sub.shape)\n",
    "print (df_train.head(3), '\\n\\n', df_test.head(3), '\\n\\n', df_sub.head(3))\n",
    "# 处理数据\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(df_train.author.values)\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(df_train.text.values, y, \n",
    "                                                  stratify = y, \n",
    "                                                  random_state = 2020, \n",
    "                                                  test_size = 0.2, shuffle = True)\n",
    "xtest = df_test.text.values\n",
    "print (xtrain.shape)\n",
    "print (xvalid.shape)\n",
    "print (xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "437a4665-1161-44ad-9ba6-0a8aae16cf1d",
    "_uuid": "e3a38494-3350-42f5-b35e-72f1ee881206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 5000, time:0.5617873668670654\n",
      "index: 10000, time:1.1098437309265137\n",
      "index: 15000, time:1.6619408130645752\n",
      "index: 20000, time:2.2036471366882324\n",
      "index: 25000, time:2.734813690185547\n",
      "Found 25929 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# # load the GloVe vectors in a dictionary:\n",
    "# embeddings_word_set = set()\n",
    "# def sent2vec_add_word(s):\n",
    "#     words = str(s).lower()\n",
    "#     words = word_tokenize(words)\n",
    "#     words = [w for w in words if not w in stop_words]\n",
    "#     words = [w for w in words if w.isalpha()]\n",
    "#     for w in words:\n",
    "#         embeddings_word_set.add(str.encode(w))\n",
    "#     return 0\n",
    "\n",
    "# temp = [sent2vec_add_word(x) for x in xtrain]\n",
    "# del temp\n",
    "# gc.collect()\n",
    "# temp = [sent2vec_add_word(x) for x in xvalid]\n",
    "# del temp\n",
    "# gc.collect()\n",
    "# temp = [sent2vec_add_word(x) for x in xtest]\n",
    "# del temp\n",
    "# gc.collect()\n",
    "\n",
    "# # %% [code]\n",
    "# # load the GloVe vectors in a dictionary:\n",
    "# embeddings_index = {}\n",
    "# f = open(data_path + '../glove840b300dtxt/glove.840B.300d.txt', 'rb')\n",
    "# f_now = open('/kaggle/working/glove840b300dtxt_now.txt', 'wb')\n",
    "# index = 0\n",
    "# pre_time = time.time()\n",
    "# glove840b300dtxt_now = []\n",
    "# for line in f: # tqdm(f):\n",
    "#     index += 1\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     if word in embeddings_word_set:\n",
    "#         embeddings_index[word] = coefs\n",
    "#         glove840b300dtxt_now.append(line)\n",
    "#     if index % 500000 == 0:\n",
    "#         print ('index: {:}, time:{:}'.format(index, time.time() - pre_time))\n",
    "# f_now.write(b''.join(glove840b300dtxt_now))\n",
    "# f_now.close()\n",
    "# f.close()\n",
    "# print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# load the GloVe vectors in a dictionary:\n",
    "embeddings_word_set = set()\n",
    "def sent2vec_add_word(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    for w in words:\n",
    "        embeddings_word_set.add(str.encode(w))\n",
    "    return 0\n",
    "\n",
    "temp = [sent2vec_add_word(x) for x in xtrain]\n",
    "del temp\n",
    "gc.collect()\n",
    "temp = [sent2vec_add_word(x) for x in xvalid]\n",
    "del temp\n",
    "gc.collect()\n",
    "temp = [sent2vec_add_word(x) for x in xtest]\n",
    "del temp\n",
    "gc.collect()\n",
    "\n",
    "# %% [code]\n",
    "# load the GloVe vectors in a dictionary:\n",
    "embeddings_index = {}\n",
    "f = open('/kaggle/input/glove840b300dtxt-spooky/glove840b300dtxt_now.txt', 'rb')\n",
    "index = 0\n",
    "pre_time = time.time()\n",
    "for line in f: # tqdm(f):\n",
    "    index += 1\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    if word in embeddings_word_set:\n",
    "        embeddings_index[word] = coefs\n",
    "    if index % 5000 == 0:\n",
    "        print ('index: {:}, time:{:}'.format(index, time.time() - pre_time))\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "de26f6d8-16b5-48e9-87f2-b38de3cbf01d",
    "_uuid": "d6dd889a-5be6-4aa1-a7d0-13baeb07f2db"
   },
   "outputs": [],
   "source": [
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            torch_tmp = list(embeddings_index[str.encode(w)])\n",
    "            M.append(torch_tmp)\n",
    "        except:\n",
    "            continue\n",
    "    if len(M) == 0:\n",
    "        M.append([0] * 300)\n",
    "    return M\n",
    "\n",
    "xtrain_glove = [sent2vec(x) for x in xtrain]\n",
    "xvalid_glove = [sent2vec(x) for x in xvalid]\n",
    "xtest_glove = [sent2vec(x) for x in xtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "6070df6b-da9d-4a9b-a86c-fdd441ac3e8e",
    "_uuid": "a093929e-ab13-4404-a9e6-f5c6984d981a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_vector_size: 300, label_size: 3\n",
      "tensor(252, device='cuda:0')\n",
      "<class 'torch.Tensor'> torch.Size([15663, 200, 300])\n"
     ]
    }
   ],
   "source": [
    "word_vector_size = len(xtrain_glove[0][0])\n",
    "label_size = 3\n",
    "print ('word_vector_size: {:}, label_size: {:}'.format(word_vector_size, label_size))\n",
    "\n",
    "xtrain_lengths = torch.LongTensor([len(x) for x in xtrain_glove]).cuda()\n",
    "print (xtrain_lengths.max())\n",
    "max_length = 200\n",
    "xtrain_torch = torch.zeros((len(xtrain_glove), max_length, word_vector_size)).float().cuda()\n",
    "for idx in range(len(xtrain_glove)):\n",
    "    seqlen = min(int(xtrain_lengths[idx].cpu().numpy()), max_length)\n",
    "    xtrain_torch[idx, :seqlen] = torch.FloatTensor(np.array(xtrain_glove[idx])[: seqlen, :])\n",
    "\n",
    "print (type(xtrain_torch), xtrain_torch.size())\n",
    "xtrain_lengths, seq_idx = xtrain_lengths.sort(0, descending = True)\n",
    "xtrain_torch = xtrain_torch[seq_idx]\n",
    "if isinstance(ytrain, np.ndarray):\n",
    "    ytrain = torch.from_numpy(ytrain).cuda()[seq_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_vector_size: 300\n",
      "input_size: 300\n",
      "hidden_size: 256\n",
      "num_layers: 1\n",
      "num_classes: 3\n",
      "learning_rate: 0.03\n",
      "batch_size: 8000\n",
      "drop_rate: 0.1\n",
      "torch.float32 torch.int64 torch.int64\n",
      "torch.Size([15663, 200, 300])\n",
      "0 2677 8000\n",
      "Counter({0: 6482, 2: 1467, 1: 51}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1/2000], Accuracy: 4563 / 15663 = 29%,  Loss: 3.9541, time: 0.5405874252319336\n",
      "0 6387 8000\n",
      "Counter({1: 3223, 2: 2403, 0: 2374}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [21/2000], Accuracy: 12007 / 15663 = 77%,  Loss: 0.6539, time: 16.156126737594604\n",
      "0 7625 8000\n",
      "Counter({1: 2793, 0: 2762, 2: 2445}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [41/2000], Accuracy: 14376 / 15663 = 92%,  Loss: 0.3270, time: 31.8060462474823\n",
      "0 7910 8000\n",
      "Counter({0: 2831, 1: 2741, 2: 2428}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [61/2000], Accuracy: 15305 / 15663 = 98%,  Loss: 0.1232, time: 47.442784786224365\n",
      "0 6239 8000\n",
      "Counter({0: 3540, 2: 3123, 1: 1337}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [81/2000], Accuracy: 12597 / 15663 = 80%,  Loss: 0.4052, time: 63.68893218040466\n",
      "0 7889 8000\n",
      "Counter({0: 2836, 1: 2737, 2: 2427}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [101/2000], Accuracy: 15273 / 15663 = 98%,  Loss: 0.1241, time: 79.19785189628601\n",
      "0 7918 8000\n",
      "Counter({0: 2834, 1: 2738, 2: 2428}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [121/2000], Accuracy: 15397 / 15663 = 98%,  Loss: 0.0753, time: 94.53248357772827\n",
      "0 7930 8000\n",
      "Counter({0: 2823, 1: 2744, 2: 2433}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [141/2000], Accuracy: 15458 / 15663 = 99%,  Loss: 0.0621, time: 110.13496017456055\n",
      "0 7918 8000\n",
      "Counter({0: 2839, 1: 2749, 2: 2412}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [161/2000], Accuracy: 15467 / 15663 = 99%,  Loss: 0.0488, time: 126.1265013217926\n",
      "0 7930 8000\n",
      "Counter({0: 2830, 1: 2749, 2: 2421}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [181/2000], Accuracy: 15488 / 15663 = 99%,  Loss: 0.0375, time: 141.8903934955597\n",
      "0 7927 8000\n",
      "Counter({0: 2833, 1: 2744, 2: 2423}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [201/2000], Accuracy: 15500 / 15663 = 99%,  Loss: 0.0353, time: 157.23981976509094\n",
      "0 7928 8000\n",
      "Counter({0: 2832, 1: 2750, 2: 2418}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [221/2000], Accuracy: 15486 / 15663 = 99%,  Loss: 0.0380, time: 173.17532587051392\n",
      "0 7929 8000\n",
      "Counter({0: 2830, 1: 2747, 2: 2423}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [241/2000], Accuracy: 15490 / 15663 = 99%,  Loss: 0.0347, time: 188.83422994613647\n",
      "0 7929 8000\n",
      "Counter({0: 2825, 1: 2742, 2: 2433}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [261/2000], Accuracy: 15489 / 15663 = 99%,  Loss: 0.0342, time: 204.42048406600952\n",
      "0 7926 8000\n",
      "Counter({0: 2836, 1: 2755, 2: 2409}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [281/2000], Accuracy: 15504 / 15663 = 99%,  Loss: 0.0331, time: 220.05159902572632\n",
      "0 7923 8000\n",
      "Counter({0: 2828, 1: 2738, 2: 2434}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [301/2000], Accuracy: 15493 / 15663 = 99%,  Loss: 0.0332, time: 236.08547234535217\n",
      "0 7915 8000\n",
      "Counter({0: 2840, 1: 2734, 2: 2426}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [321/2000], Accuracy: 15481 / 15663 = 99%,  Loss: 0.0309, time: 251.92368721961975\n",
      "0 7897 8000\n",
      "Counter({0: 2841, 1: 2719, 2: 2440}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [341/2000], Accuracy: 15473 / 15663 = 99%,  Loss: 0.0305, time: 267.4226062297821\n",
      "0 7923 8000\n",
      "Counter({0: 2839, 1: 2751, 2: 2410}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [361/2000], Accuracy: 15491 / 15663 = 99%,  Loss: 0.0310, time: 282.95950961112976\n",
      "0 7919 8000\n",
      "Counter({0: 2831, 1: 2743, 2: 2426}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [381/2000], Accuracy: 15517 / 15663 = 99%,  Loss: 0.0273, time: 298.8549840450287\n",
      "0 7932 8000\n",
      "Counter({0: 2830, 1: 2755, 2: 2415}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [401/2000], Accuracy: 15516 / 15663 = 99%,  Loss: 0.0270, time: 314.2299301624298\n",
      "0 7904 8000\n",
      "Counter({0: 2849, 1: 2725, 2: 2426}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [421/2000], Accuracy: 15488 / 15663 = 99%,  Loss: 0.0251, time: 328.55937123298645\n",
      "0 7937 8000\n",
      "Counter({0: 2824, 1: 2757, 2: 2419}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [441/2000], Accuracy: 15512 / 15663 = 99%,  Loss: 0.0339, time: 343.927800655365\n",
      "0 6033 8000\n",
      "Counter({2: 3522, 1: 2521, 0: 1957}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [461/2000], Accuracy: 12583 / 15663 = 80%,  Loss: 0.4141, time: 360.14727091789246\n",
      "0 7909 8000\n",
      "Counter({0: 2836, 1: 2744, 2: 2420}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [481/2000], Accuracy: 15373 / 15663 = 98%,  Loss: 0.0908, time: 375.4984276294708\n",
      "0 7922 8000\n",
      "Counter({0: 2836, 1: 2745, 2: 2419}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [501/2000], Accuracy: 15467 / 15663 = 99%,  Loss: 0.0512, time: 391.0442497730255\n",
      "0 7924 8000\n",
      "Counter({0: 2829, 1: 2741, 2: 2430}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [521/2000], Accuracy: 15469 / 15663 = 99%,  Loss: 0.0467, time: 406.6067888736725\n",
      "0 7913 8000\n",
      "Counter({0: 2844, 1: 2744, 2: 2412}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [541/2000], Accuracy: 15461 / 15663 = 99%,  Loss: 0.0455, time: 422.4960334300995\n",
      "0 7922 8000\n",
      "Counter({0: 2829, 1: 2737, 2: 2434}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [561/2000], Accuracy: 15480 / 15663 = 99%,  Loss: 0.0452, time: 437.9677677154541\n",
      "0 7918 8000\n",
      "Counter({0: 2837, 1: 2737, 2: 2426}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [581/2000], Accuracy: 15484 / 15663 = 99%,  Loss: 0.0384, time: 453.338853597641\n",
      "0 7919 8000\n",
      "Counter({0: 2832, 1: 2736, 2: 2432}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [601/2000], Accuracy: 15503 / 15663 = 99%,  Loss: 0.0312, time: 468.61691308021545\n",
      "0 7912 8000\n",
      "Counter({0: 2840, 1: 2734, 2: 2426}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [621/2000], Accuracy: 15483 / 15663 = 99%,  Loss: 0.0353, time: 484.74050116539\n",
      "0 7932 8000\n",
      "Counter({0: 2821, 1: 2748, 2: 2431}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [641/2000], Accuracy: 15501 / 15663 = 99%,  Loss: 0.0316, time: 500.2148873806\n",
      "0 7926 8000\n",
      "Counter({0: 2825, 1: 2742, 2: 2433}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [661/2000], Accuracy: 15500 / 15663 = 99%,  Loss: 0.0334, time: 515.952154636383\n",
      "0 7924 8000\n",
      "Counter({0: 2835, 1: 2750, 2: 2415}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [681/2000], Accuracy: 15492 / 15663 = 99%,  Loss: 0.0355, time: 531.5911138057709\n",
      "0 7930 8000\n",
      "Counter({0: 2826, 1: 2744, 2: 2430}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [701/2000], Accuracy: 15519 / 15663 = 99%,  Loss: 0.0288, time: 547.5685625076294\n",
      "0 7920 8000\n",
      "Counter({0: 2830, 1: 2740, 2: 2430}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [721/2000], Accuracy: 15491 / 15663 = 99%,  Loss: 0.0317, time: 562.861946105957\n",
      "0 7920 8000\n",
      "Counter({0: 2828, 1: 2740, 2: 2432}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [741/2000], Accuracy: 15509 / 15663 = 99%,  Loss: 0.0269, time: 578.3232486248016\n",
      "0 7934 8000\n",
      "Counter({0: 2824, 1: 2751, 2: 2425}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [761/2000], Accuracy: 15508 / 15663 = 99%,  Loss: 0.0293, time: 594.1939179897308\n",
      "0 7926 8000\n",
      "Counter({0: 2830, 1: 2745, 2: 2425}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [781/2000], Accuracy: 15511 / 15663 = 99%,  Loss: 0.0279, time: 609.8337600231171\n",
      "0 7935 8000\n",
      "Counter({0: 2820, 1: 2752, 2: 2428}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [801/2000], Accuracy: 15535 / 15663 = 99%,  Loss: 0.0255, time: 625.2591874599457\n",
      "0 7916 8000\n",
      "Counter({0: 2831, 1: 2744, 2: 2425}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [821/2000], Accuracy: 15511 / 15663 = 99%,  Loss: 0.0276, time: 640.694723367691\n",
      "0 7917 8000\n",
      "Counter({0: 2839, 1: 2740, 2: 2421}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [841/2000], Accuracy: 15492 / 15663 = 99%,  Loss: 0.0383, time: 656.453825712204\n",
      "0 7908 8000\n",
      "Counter({0: 2840, 1: 2734, 2: 2426}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [861/2000], Accuracy: 15485 / 15663 = 99%,  Loss: 0.0314, time: 672.5398018360138\n",
      "0 7916 8000\n",
      "Counter({0: 2833, 1: 2739, 2: 2428}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [881/2000], Accuracy: 15486 / 15663 = 99%,  Loss: 0.0304, time: 687.9025127887726\n",
      "0 7936 8000\n",
      "Counter({0: 2822, 1: 2751, 2: 2427}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [901/2000], Accuracy: 15511 / 15663 = 99%,  Loss: 0.0323, time: 703.5183067321777\n",
      "0 7908 8000\n",
      "Counter({0: 2847, 1: 2740, 2: 2413}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [921/2000], Accuracy: 15462 / 15663 = 99%,  Loss: 0.0336, time: 719.5217626094818\n",
      "0 7920 8000\n",
      "Counter({0: 2829, 1: 2739, 2: 2432}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [941/2000], Accuracy: 15509 / 15663 = 99%,  Loss: 0.0251, time: 735.128259897232\n",
      "0 7926 8000\n",
      "Counter({0: 2820, 1: 2744, 2: 2436}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [961/2000], Accuracy: 15495 / 15663 = 99%,  Loss: 0.0364, time: 750.4247193336487\n",
      "0 7924 8000\n",
      "Counter({0: 2821, 1: 2741, 2: 2438}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [981/2000], Accuracy: 15506 / 15663 = 99%,  Loss: 0.0278, time: 765.8838629722595\n",
      "0 7917 8000\n",
      "Counter({0: 2832, 1: 2733, 2: 2435}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1001/2000], Accuracy: 15512 / 15663 = 99%,  Loss: 0.0259, time: 781.801629781723\n",
      "0 7902 8000\n",
      "Counter({0: 2834, 1: 2727, 2: 2439}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1021/2000], Accuracy: 15471 / 15663 = 99%,  Loss: 0.0329, time: 797.3196089267731\n",
      "0 7893 8000\n",
      "Counter({0: 2816, 1: 2758, 2: 2426}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1041/2000], Accuracy: 15418 / 15663 = 98%,  Loss: 0.0446, time: 812.906445980072\n",
      "0 7917 8000\n",
      "Counter({0: 2823, 1: 2754, 2: 2423}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1061/2000], Accuracy: 15449 / 15663 = 99%,  Loss: 0.0516, time: 828.4486260414124\n",
      "0 7878 8000\n",
      "Counter({0: 2842, 1: 2719, 2: 2439}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1081/2000], Accuracy: 15386 / 15663 = 98%,  Loss: 0.0581, time: 844.6059341430664\n",
      "0 6917 8000\n",
      "Counter({0: 2823, 1: 2780, 2: 2397}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1101/2000], Accuracy: 13211 / 15663 = 84%,  Loss: 0.4978, time: 860.1117699146271\n",
      "0 4154 8000\n",
      "Counter({0: 3941, 2: 2181, 1: 1878}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1121/2000], Accuracy: 8255 / 15663 = 53%,  Loss: 0.9743, time: 875.5229194164276\n",
      "0 3816 8000\n",
      "Counter({0: 3680, 2: 2637, 1: 1683}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1141/2000], Accuracy: 7853 / 15663 = 50%,  Loss: 0.9859, time: 891.1916153430939\n",
      "0 3678 8000\n",
      "Counter({1: 4250, 2: 3009, 0: 741}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1161/2000], Accuracy: 7575 / 15663 = 48%,  Loss: 0.9983, time: 907.1565909385681\n",
      "0 3937 8000\n",
      "Counter({0: 3635, 1: 2321, 2: 2044}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1181/2000], Accuracy: 7789 / 15663 = 50%,  Loss: 1.0022, time: 922.8328590393066\n",
      "0 3655 8000\n",
      "Counter({0: 5226, 1: 1631, 2: 1143}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1201/2000], Accuracy: 7468 / 15663 = 48%,  Loss: 1.0027, time: 938.1014952659607\n",
      "0 3783 8000\n",
      "Counter({0: 3723, 2: 2153, 1: 2124}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1221/2000], Accuracy: 7608 / 15663 = 49%,  Loss: 1.0059, time: 954.1474142074585\n",
      "0 3578 8000\n",
      "Counter({0: 5586, 1: 1718, 2: 696}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1241/2000], Accuracy: 7390 / 15663 = 47%,  Loss: 1.0061, time: 969.7491014003754\n",
      "0 3820 8000\n",
      "Counter({0: 3982, 2: 2096, 1: 1922}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1261/2000], Accuracy: 7711 / 15663 = 49%,  Loss: 0.9996, time: 985.201907157898\n",
      "0 3830 8000\n",
      "Counter({0: 4010, 1: 2011, 2: 1979}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1281/2000], Accuracy: 7694 / 15663 = 49%,  Loss: 0.9988, time: 999.3708469867706\n",
      "0 3849 8000\n",
      "Counter({0: 3927, 2: 2128, 1: 1945}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1301/2000], Accuracy: 7697 / 15663 = 49%,  Loss: 1.0023, time: 1015.4580228328705\n",
      "0 3869 8000\n",
      "Counter({0: 3498, 2: 2658, 1: 1844}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1321/2000], Accuracy: 7764 / 15663 = 50%,  Loss: 0.9985, time: 1031.0143406391144\n",
      "0 3884 8000\n",
      "Counter({0: 3206, 2: 2931, 1: 1863}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1341/2000], Accuracy: 7690 / 15663 = 49%,  Loss: 1.0060, time: 1046.47300863266\n",
      "0 3894 8000\n",
      "Counter({0: 3008, 2: 2960, 1: 2032}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1361/2000], Accuracy: 7729 / 15663 = 49%,  Loss: 1.0042, time: 1061.7757420539856\n",
      "0 3825 8000\n",
      "Counter({0: 3284, 2: 2691, 1: 2025}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1381/2000], Accuracy: 7679 / 15663 = 49%,  Loss: 1.0059, time: 1077.6487393379211\n",
      "0 3838 8000\n",
      "Counter({0: 3729, 1: 2241, 2: 2030}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1401/2000], Accuracy: 7654 / 15663 = 49%,  Loss: 0.9984, time: 1093.0927402973175\n",
      "0 3783 8000\n",
      "Counter({2: 3193, 0: 2984, 1: 1823}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1421/2000], Accuracy: 7591 / 15663 = 48%,  Loss: 1.0017, time: 1108.6782846450806\n",
      "0 3917 8000\n",
      "Counter({0: 3468, 2: 2478, 1: 2054}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1441/2000], Accuracy: 7793 / 15663 = 50%,  Loss: 1.0020, time: 1123.98943400383\n",
      "0 3771 8000\n",
      "Counter({2: 3434, 0: 2619, 1: 1947}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1461/2000], Accuracy: 7651 / 15663 = 49%,  Loss: 0.9959, time: 1139.9662733078003\n",
      "0 3851 8000\n",
      "Counter({0: 3599, 2: 2286, 1: 2115}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1481/2000], Accuracy: 7731 / 15663 = 49%,  Loss: 0.9978, time: 1155.466454744339\n",
      "0 3830 8000\n",
      "Counter({0: 3275, 2: 2795, 1: 1930}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1501/2000], Accuracy: 7701 / 15663 = 49%,  Loss: 1.0029, time: 1170.9552466869354\n",
      "0 3887 8000\n",
      "Counter({0: 3493, 2: 2555, 1: 1952}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1521/2000], Accuracy: 7795 / 15663 = 50%,  Loss: 0.9882, time: 1186.5978562831879\n",
      "0 3831 8000\n",
      "Counter({0: 3555, 2: 2428, 1: 2017}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1541/2000], Accuracy: 7744 / 15663 = 49%,  Loss: 0.9973, time: 1202.5697765350342\n",
      "0 3844 8000\n",
      "Counter({0: 3354, 2: 2514, 1: 2132}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1561/2000], Accuracy: 7774 / 15663 = 50%,  Loss: 0.9981, time: 1218.1296782493591\n",
      "0 3807 8000\n",
      "Counter({0: 3931, 2: 2090, 1: 1979}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1581/2000], Accuracy: 7660 / 15663 = 49%,  Loss: 1.0013, time: 1233.4949026107788\n",
      "0 3860 8000\n",
      "Counter({0: 3602, 2: 2268, 1: 2130}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1601/2000], Accuracy: 7667 / 15663 = 49%,  Loss: 1.0020, time: 1248.9670600891113\n",
      "0 3838 8000\n",
      "Counter({0: 3690, 2: 2444, 1: 1866}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1621/2000], Accuracy: 7745 / 15663 = 49%,  Loss: 0.9965, time: 1265.1223776340485\n",
      "0 3853 8000\n",
      "Counter({0: 3780, 2: 2241, 1: 1979}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1641/2000], Accuracy: 7735 / 15663 = 49%,  Loss: 0.9988, time: 1280.558694601059\n",
      "0 3869 8000\n",
      "Counter({0: 3141, 2: 2873, 1: 1986}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1661/2000], Accuracy: 7746 / 15663 = 49%,  Loss: 0.9990, time: 1295.934777021408\n",
      "0 3906 8000\n",
      "Counter({0: 3697, 2: 2459, 1: 1844}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1681/2000], Accuracy: 7727 / 15663 = 49%,  Loss: 0.9981, time: 1311.4142127037048\n",
      "0 3827 8000\n",
      "Counter({0: 4071, 1: 1966, 2: 1963}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1701/2000], Accuracy: 7684 / 15663 = 49%,  Loss: 1.0009, time: 1327.622111082077\n",
      "0 3842 8000\n",
      "Counter({0: 3901, 2: 2091, 1: 2008}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1721/2000], Accuracy: 7713 / 15663 = 49%,  Loss: 0.9973, time: 1343.231517791748\n",
      "0 3757 8000\n",
      "Counter({2: 3352, 0: 3104, 1: 1544}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1741/2000], Accuracy: 7642 / 15663 = 49%,  Loss: 0.9984, time: 1358.5918102264404\n",
      "0 3854 8000\n",
      "Counter({0: 3583, 2: 2577, 1: 1840}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1761/2000], Accuracy: 7674 / 15663 = 49%,  Loss: 1.0057, time: 1374.7097182273865\n",
      "0 3860 8000\n",
      "Counter({0: 3456, 2: 2603, 1: 1941}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1781/2000], Accuracy: 7657 / 15663 = 49%,  Loss: 1.0018, time: 1390.2090702056885\n",
      "0 3836 8000\n",
      "Counter({0: 3393, 2: 2542, 1: 2065}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1801/2000], Accuracy: 7660 / 15663 = 49%,  Loss: 1.0062, time: 1405.8245577812195\n",
      "0 3781 8000\n",
      "Counter({0: 3292, 2: 2942, 1: 1766}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1821/2000], Accuracy: 7616 / 15663 = 49%,  Loss: 1.0018, time: 1421.1561486721039\n",
      "0 3815 8000\n",
      "Counter({0: 3948, 2: 2146, 1: 1906}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1841/2000], Accuracy: 7689 / 15663 = 49%,  Loss: 0.9951, time: 1437.050724029541\n",
      "0 3828 8000\n",
      "Counter({0: 3461, 2: 2592, 1: 1947}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1861/2000], Accuracy: 7714 / 15663 = 49%,  Loss: 0.9976, time: 1452.6129598617554\n",
      "0 3795 8000\n",
      "Counter({2: 3140, 0: 2834, 1: 2026}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1881/2000], Accuracy: 7584 / 15663 = 48%,  Loss: 1.0035, time: 1468.1447796821594\n",
      "0 3808 8000\n",
      "Counter({0: 3579, 2: 2419, 1: 2002}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1901/2000], Accuracy: 7655 / 15663 = 49%,  Loss: 1.0001, time: 1483.7645728588104\n",
      "0 3895 8000\n",
      "Counter({0: 3666, 2: 2255, 1: 2079}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1921/2000], Accuracy: 7767 / 15663 = 50%,  Loss: 0.9996, time: 1499.7164397239685\n",
      "0 3831 8000\n",
      "Counter({0: 3587, 2: 2421, 1: 1992}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1941/2000], Accuracy: 7661 / 15663 = 49%,  Loss: 0.9996, time: 1515.226990699768\n",
      "0 3799 8000\n",
      "Counter({2: 3072, 0: 2995, 1: 1933}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1961/2000], Accuracy: 7641 / 15663 = 49%,  Loss: 1.0041, time: 1530.5968251228333\n",
      "0 3856 8000\n",
      "Counter({0: 4012, 2: 2061, 1: 1927}) Counter({1: 2795, 0: 2780, 2: 2425})\n",
      "Epoch [1981/2000], Accuracy: 7747 / 15663 = 49%,  Loss: 0.9940, time: 1545.9407670497894\n"
     ]
    }
   ],
   "source": [
    "input_size = word_vector_size\n",
    "num_classes = 3\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "learning_rate = 0.03\n",
    "device = 'cuda'\n",
    "batch_size = 8000\n",
    "drop_rate = 0.1\n",
    "print (\"word_vector_size: {:}\".format(word_vector_size))\n",
    "print (\"input_size: {:}\".format(input_size))\n",
    "print (\"hidden_size: {:}\".format(hidden_size))\n",
    "print (\"num_layers: {:}\".format(num_layers))\n",
    "print (\"num_classes: {:}\".format(num_classes))\n",
    "print (\"learning_rate: {:}\".format(learning_rate))\n",
    "print (\"batch_size: {:}\".format(batch_size))\n",
    "print (\"drop_rate: {:}\".format(drop_rate))\n",
    "### 定义模型\n",
    "class simpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, drop_rate):\n",
    "        super(simpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.drop_layer = nn.Dropout(p = drop_rate)\n",
    "\n",
    "    def forward(self, x, batch_size):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        # 初始化hidden和memory cell参数\n",
    "        h0 = torch.randn(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.randn(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        # forward propagate lstm\n",
    "        encoder_outputs_packed, (h_n, h_c) = self.lstm(x, (h0, c0))\n",
    "        # print (type(encoder_outputs_packed))\n",
    "        out, lens_unpacked = nn.utils.rnn.pad_packed_sequence(encoder_outputs_packed, batch_first=True)\n",
    "        # print (type(lens_unpacked), lens_unpacked.size())\n",
    "        lens_unpacked_sub = lens_unpacked.sub(1)\n",
    "        # out = encoder_outputs_packed\n",
    "        \n",
    "        # 选取最后一个时刻的输出\n",
    "        h_n = torch.transpose(h_n, 0, 1)\n",
    "        # print (type(h_n), h_n.size())\n",
    "        out = self.fc(h_n[:, -1, :])\n",
    "        out = self.drop_layer(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "model = simpleLSTM(input_size, hidden_size, num_layers, num_classes, drop_rate = drop_rate).cuda()\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, images, labels, length):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.length = length\n",
    "\n",
    "    def __getitem__(self, index):#返回的是tensor\n",
    "        img, target, length = self.images[index], self.labels[index], self.length[index]\n",
    "        return img, target, length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "xtrain_torch = xtrain_torch.float()\n",
    "print (xtrain_torch.dtype, ytrain.dtype, xtrain_lengths.dtype)\n",
    "print (xtrain_torch.size())\n",
    "train_loader = DataLoader(MyDataset(xtrain_torch, ytrain, xtrain_lengths), batch_size = batch_size,shuffle=False)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "start_time = time.time()\n",
    "epoch_size = 2000\n",
    "for epoch in range(epoch_size):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (xtrain_batch, ytrain_batch, xtrain_length_batch) in enumerate(train_loader):\n",
    "        xtrain_length_batch = torch.clamp(xtrain_length_batch, 0, 100)\n",
    "        # print (xtrain_batch.size(), xtrain_length_batch.size())\n",
    "        embed_input_x_packed = nn.utils.rnn.pack_padded_sequence(xtrain_batch, xtrain_length_batch, batch_first=True)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(embed_input_x_packed, len(xtrain_batch))\n",
    "        # print (\"outputs.size(): {:}\".format(outputs.size()))\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += xtrain_batch.size(0)\n",
    "        correct += (predicted == ytrain_batch).sum().item()\n",
    "        \n",
    "        loss = criterion(outputs, ytrain_batch)\n",
    "\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 20 == 0 and i == 0:\n",
    "            print (i, correct, total)\n",
    "            print (Counter(predicted.cpu().numpy()), Counter(ytrain_batch.cpu().numpy()),)\n",
    "    if epoch % 20 == 0:\n",
    "        print('Epoch [{}/{}], Accuracy: {} / {} = {:.0f}%,  Loss: {:.4f}, time: {:}'. \\\n",
    "              format(epoch+1, epoch_size, correct, total, (100 * correct / total), loss.item(), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([3916, 200, 300])\n",
      "Test Accuracy of the model on the test: 48.72318692543411%\n",
      "[2 1 0 1 1 0 0 1 2 2]\n",
      "Counter({0: 1978, 2: 1139, 1: 799})\n",
      "Counter({0: 1580, 2: 1209, 1: 1127})\n",
      "Counter({0: 6320, 2: 4835, 1: 4508})\n"
     ]
    }
   ],
   "source": [
    "xvalid_lengths = torch.FloatTensor([len(x) for x in xvalid_glove]).cuda()\n",
    "xvalid_torch = torch.zeros((len(xvalid_glove), max_length, word_vector_size)).float().cuda()\n",
    "for idx in range(len(xvalid_glove)):\n",
    "    seqlen = min(int(xvalid_lengths[idx].cpu().numpy()), max_length)\n",
    "    xvalid_torch[idx, :seqlen] = torch.FloatTensor(np.array(xvalid_glove[idx])[: seqlen, :])\n",
    "\n",
    "print (type(xvalid_torch), xvalid_torch.size())\n",
    "xvalid_lengths, seq_idx_valid = xvalid_lengths.sort(0, descending = True)\n",
    "xvalid_torch = xvalid_torch[seq_idx_valid]\n",
    "if isinstance(yvalid, np.ndarray):\n",
    "    yvalid = torch.from_numpy(yvalid).cuda()[seq_idx_valid]\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    xvalid_length_batch = torch.clamp(xvalid_lengths, 0, 100).cuda()\n",
    "#     print (type(xvalid_length_batch), xvalid_length_batch.device, xvalid_length_batch.size())\n",
    "#     print (type(xvalid_torch), xvalid_torch.device, xvalid_torch.size())\n",
    "    embed_input_x_packed = nn.utils.rnn.pack_padded_sequence(xvalid_torch, xvalid_length_batch, batch_first=True)\n",
    "    outputs = model(embed_input_x_packed, xvalid_torch.size(0))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total = xvalid_torch.size(0)\n",
    "    correct = (predicted == yvalid).sum().item()\n",
    "print('Test Accuracy of the model on the test: {}%'.format(100 * correct / total))\n",
    "print (predicted.cpu().numpy()[: 10])\n",
    "print (Counter(predicted.cpu().numpy()))\n",
    "print (Counter(yvalid.cpu().numpy()))\n",
    "print (Counter(ytrain.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([8392, 200, 300])\n",
      "torch.Size([8392, 3])\n",
      "        id       EAP       HPL       MWS\n",
      "0  id20462  0.234247  0.253187  0.512566\n",
      "1  id22158  0.283595  0.565837  0.150568\n",
      "2  id23419  0.439435  0.251868  0.308696\n"
     ]
    }
   ],
   "source": [
    "xtest_lengths = torch.FloatTensor([len(x) for x in xtest_glove]).cuda()\n",
    "xtest_torch = torch.zeros((len(xtest_glove), max_length, word_vector_size)).float().cuda()\n",
    "for idx in range(len(xtest_glove)):\n",
    "    seqlen = min(int(xtest_lengths[idx].cpu().numpy()), max_length)\n",
    "    xtest_torch[idx, :seqlen] = torch.FloatTensor(np.array(xtest_glove[idx])[: seqlen, :])\n",
    "\n",
    "print (type(xvalid_torch), xtest_torch.size())\n",
    "xtest_lengths, seq_idx_test = xtest_lengths.sort(0, descending = True)\n",
    "xtest_torch = xtest_torch[seq_idx_test]\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    xtest_length_batch = torch.clamp(xtest_lengths, 0, 100).cpu()\n",
    "    embed_input_x_packed = nn.utils.rnn.pack_padded_sequence(xtest_torch, xtest_length_batch, batch_first=True)\n",
    "    outputs = model(embed_input_x_packed, xtest_torch.size(0))\n",
    "print (outputs.size())\n",
    "\n",
    "dim1_softmax = nn.Softmax(dim = 1)\n",
    "outputs = dim1_softmax(outputs)\n",
    "\n",
    "test_id = df_sub['id'].values\n",
    "test_id = test_id[list(seq_idx_test.cpu().numpy())]\n",
    "df_sub_test = pd.DataFrame(data = outputs.cpu().numpy(), columns = ['EAP', 'HPL', 'MWS'])\n",
    "df_sub_test['id'] = test_id\n",
    "df_sub_test = df_sub_test[['id', 'EAP', 'HPL', 'MWS']]\n",
    "df_sub_test.to_csv('/kaggle/working/sub_20200712_01.csv', index = False)\n",
    "print (df_sub_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
